{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing and importing dependencies"
      ],
      "metadata": {
        "id": "E9Gc12D1bomE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qqy9o2SlyLLn"
      },
      "outputs": [],
      "source": [
        "! pip install diffusers[training] accelerate transformers\n",
        "! pip install diffusers[\"torch\"]\n",
        "! pip install git+https://github.com/huggingface/diffusers\n",
        "! pip install torch-fidelity\n",
        "! pip uninstall torch torchvision torchaudio\n",
        "! pip install torch torchvision torchaudio\n",
        "! pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW1N0ICOya50"
      },
      "outputs": [],
      "source": [
        "! accelerate config default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jv0Z2Gpxy5F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as F\n",
        "from torchmetrics.image.kid import KernelInceptionDistance\n",
        "from diffusers import DiffusionPipeline, StableDiffusionPipeline\n",
        "from diffusers.utils import make_image_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "NZHxiNHrbmTM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_reiMfeay3dU"
      },
      "outputs": [],
      "source": [
        "! accelerate launch textual_inversion.py --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" --train_data_dir=\"/content/IshidaSui\" --learnable_property=\"style\" --placeholder_token=\"<sotonami>\" --initializer_token=\"anime\" --resolution=512 --train_batch_size=8 --gradient_accumulation_steps=1 --max_train_steps=10000 --learning_rate=5.0e-04 --scale_lr --lr_scheduler=\"constant\" --lr_warmup_steps=0 --output_dir=\"/content/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning on number of training steps"
      ],
      "metadata": {
        "id": "5XXKH5TTb3YN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG2vm4OkZjMx"
      },
      "outputs": [],
      "source": [
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "generator = [torch.Generator(device=\"cuda\").manual_seed(i) for i in range(4)]\n",
        "prompt = \"A painting of Kaneki Ken in the style of <sotonami>\"\n",
        "\n",
        "images = []\n",
        "for i in range(1, 21):\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(model_id, generator=generator, torch_dtype=torch.float16, use_safetensors=True).to(\"cuda\")\n",
        "  pipe.load_textual_inversion(\"learned_embeds-steps-\" + str(i * 500) + \".safetensors\")\n",
        "  for img in pipe(prompt, num_inference_steps=50, num_images_per_prompt=4).images:\n",
        "    images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xgF84LIsgesS"
      },
      "outputs": [],
      "source": [
        "make_image_grid(images[:32], rows=8, cols=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OY2qtMKOrrJj"
      },
      "outputs": [],
      "source": [
        "make_image_grid(images[32:64], rows=8, cols=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vyhhhNQ2sm0I"
      },
      "outputs": [],
      "source": [
        "make_image_grid(images[64:], rows=4, cols=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image generation script"
      ],
      "metadata": {
        "id": "GmbrEgomcApA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C2II0tS0mWYf"
      },
      "outputs": [],
      "source": [
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "prompt = \"A painting of Kaneki in the style of <sotonami>\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, use_safetensors=True).to(\"cuda\")\n",
        "pipe.load_textual_inversion(\"sotonami.safetensors\")\n",
        "\n",
        "images = pipe(prompt, num_inference_steps=50, num_images_per_prompt=16).images\n",
        "make_image_grid(images, rows=4, cols=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "28tl2SFVdUkX"
      },
      "outputs": [],
      "source": [
        "make_image_grid(images, rows=4, cols=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing KID"
      ],
      "metadata": {
        "id": "hDQCzdxjcZGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfOCCiS9nhr_"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image):\n",
        "    image = torch.tensor(image).unsqueeze(0)\n",
        "    image = image.permute(0, 3, 1, 2) / 255.0\n",
        "    return image\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "dataset_path = \"/content/Kamao\"\n",
        "image_paths = sorted([os.path.join(dataset_path, x) for x in os.listdir(dataset_path)])\n",
        "real_images = [np.array(Image.open(path).convert(\"RGB\")) for path in image_paths]\n",
        "real_images = torch.cat([preprocess_image(image) for image in real_images])\n",
        "\n",
        "fake_images = images\n",
        "fake_images = torch.cat([transform(image).unsqueeze(0) for image in fake_images])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6SWnVHtnlmq"
      },
      "outputs": [],
      "source": [
        "kid = KernelInceptionDistance(normalize=True, subset_size=8)\n",
        "kid.update(real_images, real=True)\n",
        "kid.update(fake_images, real=False)\n",
        "\n",
        "print(f\"KID: {kid.compute()}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}